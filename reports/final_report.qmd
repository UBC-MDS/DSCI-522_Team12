---
title: "Analysis of Customer Complaints on US Financial Products"
author:   
  - Ty Andrews  
  - Dhruvi Nishar
  - Luke Yang
execute: 
  echo: false
bibliography: assets/references.bib
format:
  pdf:
    toc: true
    number-sections: true
    colorlinks: true
  html:
    toc: true
    number-sections: true
    colorlinks: true
params: 
  output_file: "reports"
fig-cap-location: top
---

```{r, include=FALSE}
library(tidyverse)
library(knitr)
```

## Summary

Here we used multiple classification algorithms to predict whether a financial product consumer will dispute a complaint made to the Consumer Financial Protection Bureaus' (CFPB) Consumer Complaints Database[@COMPL_DB].

## Introduction

As of 2022, the CFPB receives over 60,000 consumer complaints a month related to companies financial products. Between December 2011 and November 2022 over 140,000 complaints were disputed by consumers costing both the companies and CFPB time and money.

Complaints can be responded to by the company in multiple ways but each consumer has the opportunity to dispute the provided response. These disputes are likely costly to both the CFPB and the companies for which they are raised so being able to anticipate whether a complaint will be disputed has the potential to save both time and money for companies and the CFPB alike. Especially, as we observed that the number of complaints spikes near 2022 (Figure 1), it is essential to understand the tactics of handling these complaints.

![Figure 1. Complaints Over Timeline](assets/complaints_over_time_line.png){alt="Figure 1. Complaints Over Timeline"}

## Methods

### Data

We used pandas[@pandas], scikit-learn[@scikit-learn], and TidyVerse [@tidyverse] to collect, analyze, and summarize our data. The CFPB database contains \~3 million complaints starting from December 2011 all the way up to November 2022 when this report was written. Approximately 4.8% of all complaints are disputed, with the \~75.1% of complaints having an unknown dispute status. Figure 2 below shows the balance of dispute status.

![Figure 2. Class Imbalance in the Target Column](assets/disputed_bar.png)

Each field has varying amounts of missing values as can be seen in Table 1 below. Fields such as tag where there are numerous entries missing values were removed from the analysis. Individual complaints with missing information were removed from the data-set for analysis since the data set is large enough to still have a significant number of training examples for the analysis (\~20,000).

```{r, message=FALSE}
table_data <- read_csv("./assets/unique_counts.csv") |>
  subset( select = -c(1) ) |>
  tail(-1)
kable(table_data, 
      caption = "Table 1. Unique and missing value counts by data feature.",
      col.names = c("Fields", "Valid Count", "Unique Count"),
      align = "lcc"
      )

```

### Analysis

A predictive approach using multiple classification models was used to attempt to predict whether a consumer would dispute a complaint or not.

Feature pre-processing approach and rationale is as follows:

Table 2: Feature selection and encodings.

+------------------------------+---------------------+--------------------------------------------+
| Features                     | Preprocessing Step  | Rationale                                  |
+==============================+=====================+============================================+
| consumer_complaint_narrative | CountVectorizer     | High Amount of Unique Textual Data         |
|                              |                     |                                            |
|                              | max_features = 1000 |                                            |
+------------------------------+---------------------+--------------------------------------------+
| product                      | OneHotEncoder       | Each field is categorical                  |
|                              |                     |                                            |
| sub_product                  | drop = "if_binary"  |                                            |
|                              |                     |                                            |
| issue                        |                     |                                            |
|                              |                     |                                            |
| company_public_response      |                     |                                            |
|                              |                     |                                            |
| company                      |                     |                                            |
|                              |                     |                                            |
| company_response_to_consumer |                     |                                            |
+------------------------------+---------------------+--------------------------------------------+
| consumer_consent_provided    | dropped             | Only one value in this column              |
+------------------------------+---------------------+--------------------------------------------+

: These features were passed into a column transformer, which was then integrated with five different estimator for prediction.

## Results & Discussion

We applied the `DummyClassifier`, `LogisticRegression`, `Naive Bayes`, `SVC`, and `RandomForestClassifier` to predict the target whether the customer disputed. The models were applied using default parameters and a five-fold cross-validation were applied using the training split. We examined and recorded the accuracy, precision, recall, and f1 scores to be the metrics evaluating the models. The results of the cross validation were as follows:

```{r, message=FALSE}
table_data <- read.csv("./assets/results.csv") 
names(table_data)[1] <- ''
  
kable(table_data, 
      caption = "Table 3. Model Performance and Score.",
      col.names = c("Metric", "Dummy", "Logistic Regression", "Naive Bayes", "SVC", " Random Forest"),
      align = "cccccc"
)
```

Figure 3 below illustrates a visual representation of the performance of the models. We observe a high accuracy of the `DummyClassifier`. Given the imbalance of the class, the accuracy would not be an important metric in this problem. Instead, from the company's perspective, we focus more on improving the precision, the recall, and the f1 score. Noticeably the company likely wants to spot the people who are going to dispute, thus, the recall score here is more important compared to precision.

![Figure 3: Performance of Different Models on Different Metrics](assets/model_performance.png){fig-alt="Performance of Different Models on Different Metrics" fig-align="center"}

The results above motivates us to choose `LogisticRegression` as the final estimator. It has one of the overall highest f1 scores at 0.368 and among the recall is among highest scores. Though it sacrifices some accuracy, the precision, recall, and f1 scores are significantly improved uon the dummy classifier and competitive with the other models evaluated. We also see that `SVC` gives slightly higher scores than `LogisticRegression`; however, in Table 2 we see that it takes substantially more time to train and cross validate. in addition, due to the complexity of the model we also lose a degree of model incontestability. Overall, we choose `LogisticRegression` over `SVC` due to its scalability and interpretability.

Unfortunately, an f1 score of 0.368 for `LogisticRegression` is quite low and unlikely to be particularly useful in the broader business sense. This analysis can be used as the basis to understand what target f1, precision or recall target scores should be set for further analysis.

## Conclusion

The analysis in this reports focuses on using a machine learning approach to predict whether the consumer is going to dispute after the company's response. We processed the features such as the product, consumer's complaints, and company's responses. We trained five different models that optimized the f1 score and chose `LogisticRegression` as a suitable estimator for the first pass at attempting to predict whether consumers dispute their complaints. Next steps would be evaluating the impact of the chosen models performance and then deciding whether to try and refine further to improve the model.

## References
